{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train = pd.read_csv('F:/Jupyter_Program/Algorithm/DCIC/train_dataset.csv')\n",
    "    \n",
    "    label = train['信用分'].values\n",
    "    del train['信用分']\n",
    "    \n",
    "    test = pd.read_csv('F:/Jupyter_Program/Algorithm/DCIC/test_dataset.csv')\n",
    "    test_id = test['用户编码'].values\n",
    "    \n",
    "    data = pd.concat([train,test], axis=0, ignore_index=True)\n",
    "    del data['用户编码']\n",
    "    \n",
    "    return data, label, test_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data):\n",
    "    \"\"\"\n",
    "    data：both training and testing data\n",
    "    \"\"\"\n",
    "    # 用众数填充年龄为0的数据\n",
    "    data.loc[data['用户年龄']==0, '用户年龄'] = data['用户年龄'].mode() \n",
    "    \n",
    "    # 两个重要性比较高的特征\n",
    "    data['用户网龄（年）'] = data['用户网龄（月）']/12\n",
    "    data['相对网龄'] = data['用户年龄']/(data['用户网龄（年）']+1)\n",
    "    data['网龄年龄差'] = data['用户年龄'] - data['用户网龄（年）']\n",
    "    \n",
    "    # 构造费用相关的一些特征，衡量消费积极性，强特\n",
    "    data['缴费金额能否覆盖当月账单'] = data['缴费用户最近一次缴费金额（元）'] - data['用户账单当月总费用（元）']\n",
    "    data['最近一次交费是否超过平均消费额'] = data['缴费用户最近一次缴费金额（元）'] - data['用户近6个月平均消费值（元）']\n",
    "    data['当月账单是否超过平均消费额'] = data['用户账单当月总费用（元）'] - data['用户近6个月平均消费值（元）']\n",
    "     \n",
    "    data['近半年账单'] = data['用户近6个月平均消费值（元）']*6 + data['用户账单当月总费用（元）']\n",
    "    data['通话人均花费'] = data['用户账单当月总费用（元）'] / (data['当月通话交往圈人数']+1)\n",
    "    \n",
    "    # 根据缴费金额是否整数，判断缴费方式\n",
    "    def ways(x):\n",
    "        if x==0:\n",
    "            return -1\n",
    "        elif x%10==0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    data['缴费方式'] = data['缴费用户最近一次缴费金额（元）'].map(lambda x:ways(x))\n",
    "    data = pd.get_dummies(data, columns=['缴费方式'])\n",
    "    \n",
    "    # 参考开源，新加的\n",
    "    data['话费稳定性'] = data['用户账单当月总费用（元）']/(data['用户近6个月平均消费值（元）']+1)\n",
    "    data['余额稳定性'] = data['用户账单当月总费用（元）']/(data['用户当月账户余额（元）']+1)\n",
    "    \n",
    "        \n",
    "    data['次数'] = data['当月网购类应用使用次数'] + data['当月物流快递类应用使用次数']+data['当月金融理财类应用使用总次数'] + data['当月视频播放类应用使用次数']+ data['当月飞机类应用使用次数'] + data['当月火车类应用使用次数'] + data['当月旅游资讯类应用使用次数']\n",
    "    \n",
    "    \n",
    "    # 赛事方微信公众号透露的信息\n",
    "    data['网龄十年'] =data['用户网龄（月）'].map(lambda x: 1 if x>=10 else 0)\n",
    "         \n",
    "    data['是否去过高档商场'] = data['当月是否逛过福州仓山万达'] + data['当月是否到过福州山姆会员店']\n",
    "    data['是否去过高档商场'] = data['是否去过高档商场'].map(lambda x: 1 if x>=1 else 0)\n",
    "\n",
    "    # 相乘组合特征\n",
    "    data['是否商场_旅游'] = data['是否去过高档商场'] * data['当月是否景点游览']\n",
    "    data['是否商场_体育馆'] = data['是否去过高档商场'] * data['当月是否体育场馆消费']\n",
    "    data['是否商场_电影'] = data['是否去过高档商场'] * data['当月是否看电影'] \n",
    "    data['是否体育馆_旅游'] = data['当月是否体育场馆消费'] * data['当月是否景点游览']\n",
    "    data['是否电影_旅游'] = data['当月是否看电影'] * data['当月是否景点游览']\n",
    "    data['是否电影_体育馆'] = data['当月是否看电影'] * data['当月是否体育场馆消费']    \n",
    "    \n",
    "    data['是否商场_旅游_体育馆'] = data['是否去过高档商场'] * data['当月是否景点游览'] * data['当月是否体育场馆消费']\n",
    "    data['是否商场_电影_体育馆'] = data['是否去过高档商场'] * data['当月是否看电影'] * data['当月是否体育场馆消费']\n",
    "    data['是否商场_电影_旅游'] = data['是否去过高档商场'] * data['当月是否看电影'] * data['当月是否景点游览']\n",
    "    data['是否体育馆_电影_旅游'] = data['当月是否体育场馆消费'] * data['当月是否看电影'] * data['当月是否景点游览']\n",
    "    \n",
    "    data['是否商场_体育馆_电影_旅游'] = data['是否去过高档商场'] * data['当月是否体育场馆消费'] * data['当月是否看电影'] * data['当月是否景点游览']\n",
    "    \n",
    "    \n",
    "    # 把这些连续的特征离散化\n",
    "    data['交通类应用使用次数'] = data['当月飞机类应用使用次数'] + data['当月火车类应用使用次数']\n",
    "    \n",
    "    discrete_features = ['交通类应用使用次数','当月物流快递类应用使用次数','当月飞机类应用使用次数',\n",
    "                         '当月火车类应用使用次数','当月旅游资讯类应用使用次数']\n",
    "    \n",
    "    def map_discrete(x):\n",
    "        if x == 0:\n",
    "            return 0\n",
    "        elif x <= 5:\n",
    "            return 1\n",
    "        elif x<=15:\n",
    "            return 2\n",
    "        elif x <=50:\n",
    "            return 3\n",
    "        elif x<=100:\n",
    "            return 4\n",
    "        else:\n",
    "            return 5\n",
    "        \n",
    "    for col in discrete_features:\n",
    "        data[col] = data[col].map(lambda x:map_discrete(x))\n",
    "        \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对数据的基本的处理（预处理）\n",
    "def base_process(data):\n",
    "    transform_features = ['相对网龄','网龄年龄差','用户年龄','用户网龄（月）','当月通话交往圈人数',\n",
    "        '最近一次交费是否超过平均消费额','近三个月月均商场出现次数','当月网购类应用使用次数',\n",
    "        '当月物流快递类应用使用次数','当月账单是否超过平均消费额','当月金融理财类应用使用总次数',\n",
    "        '当月视频播放类应用使用次数','当月飞机类应用使用次数','当月火车类应用使用次数',\n",
    "        '当月旅游资讯类应用使用次数','通话人均花费','次数']\n",
    "    \n",
    "    \n",
    "    user_bill_features = [ '缴费用户最近一次缴费金额（元）', '用户近6个月平均消费值（元）',\n",
    "                        '用户账单当月总费用（元）', '用户当月账户余额（元）']\n",
    "    \n",
    "    log_features = ['当月网购类应用使用次数','当月金融理财类应用使用总次数',\n",
    "        '当月视频播放类应用使用次数','次数']\n",
    "    \n",
    "    for col in transform_features + user_bill_features + log_features:\n",
    "        up_limit = np.percentile(data[col].values,99.9)\n",
    "        down_limit = np.percentile(data[col].values,0.1)\n",
    "        data[col].loc[data[col] > up_limit] = up_limit\n",
    "        data[col].loc[data[col] < down_limit] = down_limit\n",
    "            \n",
    "    # 平滑数据，对数化，x 变成 log（1+x）\n",
    "    for col in user_bill_features+ log_features:\n",
    "        data[col] = data[col].map(lambda x : np.log1p(x))\n",
    "    # loc 按索引值定位；iloc 按索引位置定位\n",
    "        \n",
    "    train, test = data[:50000], data[50000:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、模型构造和调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:4291: RuntimeWarning: Invalid value encountered in percentile\n",
      "  interpolation=interpolation)\n",
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "data, label, test_id = load_data()\n",
    "data = get_features(data)\n",
    "train, test = base_process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = lgb.LGBMRegressor(boosting_type='gbdt', num_leaves=20, max_depth=-1,\n",
    "                learning_rate=0.015,n_estimators=5000,subsample=0.8,objective='mae',\n",
    "                subsample_freq=1,colsample_bytree=0.7,reg_alpha=2.2,reg_lambda=1.2,\n",
    "                random_state=2019,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = lgb.LGBMRegressor(boosting_type='gbdt',num_leaves=20,max_depth=-1,\n",
    "                learning_rate=0.015,n_estimators=5000,subsample=0.8,objective='rmse',\n",
    "                subsample_freq=1,colsample_bytree=0.7,reg_alpha=1.6,reg_lambda=1.8,\n",
    "                random_state=2018,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = XGBRegressor(max_depth=4,learning_rate=0.03,n_estimators=2500,silent=True,\n",
    "            objective='reg:linear',booster='gbtree',n_jobs=-1,gamma=0,\n",
    "            subsample=0.8,colsample_bytree=0.7,colsample_bylevel=1,reg_alpha=0.03,reg_lambda=0.8,\n",
    "            scale_pos_weight=1,base_score=0.5,random_state=2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = XGBRegressor(max_depth=4,learning_rate=0.03,n_estimators=2500,silent=True,\n",
    "            objective='reg:linear',booster='gbtree',n_jobs=-1,gamma=0,\n",
    "            subsample=0.8,colsample_bytree=0.7,colsample_bylevel=1,reg_alpha=0.05,reg_lambda=1.3,\n",
    "            scale_pos_weight=1,base_score=0.5,random_state=2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10,random_state=2015,shuffle=False)\n",
    "best_score = []\n",
    "sub_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 140 rounds.\n",
      "[200]\ttraining's l1: 15.3377\tvalid_1's l1: 16.2645\n",
      "[400]\ttraining's l1: 14.497\tvalid_1's l1: 15.473\n",
      "[600]\ttraining's l1: 14.2158\tvalid_1's l1: 15.3331\n",
      "[800]\ttraining's l1: 14.0225\tvalid_1's l1: 15.2795\n",
      "[1000]\ttraining's l1: 13.8623\tvalid_1's l1: 15.2391\n",
      "[1200]\ttraining's l1: 13.7213\tvalid_1's l1: 15.2226\n",
      "[1400]\ttraining's l1: 13.5922\tvalid_1's l1: 15.2078\n",
      "[1600]\ttraining's l1: 13.4725\tvalid_1's l1: 15.1932\n",
      "[1800]\ttraining's l1: 13.3633\tvalid_1's l1: 15.1838\n",
      "[2000]\ttraining's l1: 13.2575\tvalid_1's l1: 15.1788\n",
      "[2200]\ttraining's l1: 13.1569\tvalid_1's l1: 15.1741\n",
      "[2400]\ttraining's l1: 13.0636\tvalid_1's l1: 15.1744\n",
      "[2600]\ttraining's l1: 12.9729\tvalid_1's l1: 15.1683\n",
      "[2800]\ttraining's l1: 12.8861\tvalid_1's l1: 15.1624\n",
      "[3000]\ttraining's l1: 12.8046\tvalid_1's l1: 15.1607\n",
      "[3200]\ttraining's l1: 12.7258\tvalid_1's l1: 15.1579\n",
      "[3400]\ttraining's l1: 12.6501\tvalid_1's l1: 15.1543\n",
      "Early stopping, best iteration is:\n",
      "[3445]\ttraining's l1: 12.6339\tvalid_1's l1: 15.1528\n",
      "Training until validation scores don't improve for 140 rounds.\n",
      "[200]\ttraining's rmse: 19.8901\tvalid_1's rmse: 21.3243\n",
      "[400]\ttraining's rmse: 18.8319\tvalid_1's rmse: 20.1264\n",
      "[600]\ttraining's rmse: 18.4712\tvalid_1's rmse: 19.9272\n",
      "[800]\ttraining's rmse: 18.2232\tvalid_1's rmse: 19.8503\n",
      "[1000]\ttraining's rmse: 18.0124\tvalid_1's rmse: 19.8014\n",
      "[1200]\ttraining's rmse: 17.8201\tvalid_1's rmse: 19.7757\n",
      "[1400]\ttraining's rmse: 17.6351\tvalid_1's rmse: 19.7504\n",
      "[1600]\ttraining's rmse: 17.4714\tvalid_1's rmse: 19.738\n",
      "[1800]\ttraining's rmse: 17.309\tvalid_1's rmse: 19.724\n",
      "[2000]\ttraining's rmse: 17.1505\tvalid_1's rmse: 19.7192\n",
      "[2200]\ttraining's rmse: 17.0029\tvalid_1's rmse: 19.7157\n",
      "Early stopping, best iteration is:\n",
      "[2081]\ttraining's rmse: 17.0902\tvalid_1's rmse: 19.714\n"
     ]
    }
   ],
   "source": [
    "for i,(train_index,val_index) in enumerate(kf.split(train,label)):\n",
    "        X_train = train.loc[train_index,:]\n",
    "        y_train = label[train_index]\n",
    "        X_val = train.loc[val_index,:]\n",
    "        y_val = label[val_index]\n",
    "        \n",
    "        clf1.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n",
    "                 eval_metric='mae',early_stopping_rounds=140,verbose=200)\n",
    "        pred_val1 = clf1.predict(X_val,num_iteration=clf1.best_iteration_)\n",
    "        val1_mae = mean_absolute_error(y_val,np.round(pred_val1))\n",
    "        pred_test1 = clf1.predict(test,num_iteration = clf1.best_iteration_)\n",
    "        \n",
    "        clf2.fit(X_train,y_train,eval_set=[(X_train,y_train),(X_val,y_val)],\n",
    "                 eval_metric='rmse',early_stopping_rounds=140,verbose=200)\n",
    "        pred_val2 = clf2.predict(X_val,num_iteration = clf2.best_iteration_)\n",
    "        val2_mae = mean_absolute_error(y_val,np.round(pred_val2))\n",
    "        pred_test2 = clf2.predict(test,num_iteration = clf2.best_iteration_)\n",
    "    \n",
    "       \n",
    "        pred_val = np.round(pred_val1*0.5 + pred_val2*0.5)\n",
    "        vali_mae = mean_absolute_error(y_val,pred_val)\n",
    "        best_score.append(1/(1+vali_mae))\n",
    "        \n",
    "        pred_test = np.round(pred_test1*0.5 + pred_test2*0.5)\n",
    "        sub_list.append(pred_test)\n",
    "        \n",
    " \n",
    "        print('Round:{:.1f},clf1 score:{:.7f},clf2 score:{:.7f},fusion score:{:.7f}\\n'.\n",
    "             format(i+1,1/(1+val1_mae),1/(1+val2_mae),1/(1+vali_mae)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前两次的结果比较差，舍弃以后模型表现有提升\n",
    "pred_test = np.mean(np.array(sub_list[2:]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = pred_test.astype('int64')\n",
    "result = pd.Series(pred_test, name='score')\n",
    "submission = pd.concat([pd.Series(test_id, name='id'), result], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('F:/Jupyter_Program/Algorithm/DCIC/submit_v4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importance_features = []\n",
    "for i in range(0,44):\n",
    "    importance_features.append((clf1.feature_importances_[i], X_train.columns[i]))\n",
    "\n",
    "importance_features.sort(reverse=True)\n",
    "importance_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(best_score[2:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
